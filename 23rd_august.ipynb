{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d69d707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration: Set your roll number here\n",
    "ROLL_NUMBER = \"22bec021\"  # Replace with your actual roll number\n",
    "\n",
    "# Input file paths\n",
    "LECTURE_TRANSCRIPT_PATH = \"C:/Users/jallu/Downloads/23Aug2025 T+S(Agentic AI)/23Aug2025 T+S(Agentic AI)/Agentic AI (2025-08-23 09_02 GMT+5_30) - Transcript.docx\"\n",
    "STUDENT_SUMMARIES_PATH = \"C:/Users/jallu/Downloads/23Aug2025 T+S(Agentic AI)/23Aug2025 T+S(Agentic AI)/Attendance + Summary in context learning.xlsx\"\n",
    "\n",
    "# Output file path\n",
    "OUTPUT_FILE_PATH = f\"Gradedresults_23rd_august.xlsx\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a182d6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jallu\\OneDrive\\Desktop\\Quiz\\quizenv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All required packages installed successfully!\n"
     ]
    }
   ],
   "source": [
    "# Install required packages if not already installed\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package, import_name=None):\n",
    "    \"\"\"\n",
    "    Install a package if not already installed.\n",
    "    \n",
    "    Args:\n",
    "        package (str): Package name for pip install\n",
    "        import_name (str): Name to use for import (if different from package name)\n",
    "    \"\"\"\n",
    "    if import_name is None:\n",
    "        # Map package names to their import names\n",
    "        import_map = {\n",
    "            \"python-docx\": \"docx\",\n",
    "            \"scikit-learn\": \"sklearn\"\n",
    "        }\n",
    "        import_name = import_map.get(package, package.replace(\"-\", \"_\"))\n",
    "    \n",
    "    try:\n",
    "        __import__(import_name)\n",
    "    except ImportError:\n",
    "        print(f\"Installing {package}...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package], \n",
    "                            stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "# Install required packages\n",
    "packages = [\n",
    "    (\"python-docx\", \"docx\"),\n",
    "    (\"pandas\", \"pandas\"),\n",
    "    (\"openpyxl\", \"openpyxl\"),\n",
    "    (\"sentence-transformers\", \"sentence_transformers\"),\n",
    "    (\"numpy\", \"numpy\"),\n",
    "    (\"scikit-learn\", \"sklearn\")\n",
    "]\n",
    "\n",
    "for package, import_name in packages:\n",
    "    install_package(package, import_name)\n",
    "\n",
    "print(\"All required packages installed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77b921fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully (NLTK has been removed).\n"
     ]
    }
   ],
   "source": [
    "# Import all required libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from docx import Document\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import warnings\n",
    "import re  # <-- ADDED THIS (replaces nltk)\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully (NLTK has been removed).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "122a27d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded lecture transcript (80986 characters)\n",
      "\n",
      "First 500 characters of transcript:\n",
      "Agentic AI (2025-08-23 09:02 GMT+5:30) - Transcript\n",
      "Attendees\n",
      "A M D PRADEEP, ABHAY TIWARI, ABHISHEK BUDDIGA, AMAN CHAURASIA, AMOD ADARSH, Amrita Kadam, AMRITA KADAM, ANNEM VENKATA KISHAN KUMAR REDDY IIIT Dharwad, ANUJA GUPTA, ARAVIND BASINI, ARYAN PRATIK, Ashutosh G Singh, ATLA SMARAN REDDY, AVISHAKULA JEEVAN KUMAR, BADA POOJITHA, BANDARU USHA NAGA SRI, BASWA TANUSREE REDDY, BOBBALACHINNOLLA JASWANTH REDDY, BONGU ASHISH IIIT Dharwad, BYREDDY VASUDEVA REDDY, CHAITRA V KATTIMANI IIIT Dharwad, DARS...\n"
     ]
    }
   ],
   "source": [
    "def load_lecture_transcript(docx_path):\n",
    "    \"\"\"\n",
    "    Load and extract text from a DOCX file containing the lecture transcript.\n",
    "    \n",
    "    Args:\n",
    "        docx_path (str): Path to the DOCX file\n",
    "    \n",
    "    Returns:\n",
    "        str: Full text content of the lecture transcript\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(docx_path):\n",
    "            raise FileNotFoundError(f\"Lecture transcript file not found: {docx_path}\")\n",
    "        \n",
    "        doc = Document(docx_path)\n",
    "        full_text = []\n",
    "        \n",
    "        # Extract text from all paragraphs\n",
    "        for paragraph in doc.paragraphs:\n",
    "            if paragraph.text.strip():  # Skip empty paragraphs\n",
    "                full_text.append(paragraph.text.strip())\n",
    "        \n",
    "        # Join all paragraphs with newlines\n",
    "        transcript = \"\\n\".join(full_text)\n",
    "        \n",
    "        # Validate that transcript is not empty\n",
    "        if len(transcript.strip()) < 50:\n",
    "            raise ValueError(\"Lecture transcript appears to be empty or too short. Please check the file.\")\n",
    "        \n",
    "        print(f\"Successfully loaded lecture transcript ({len(transcript)} characters)\")\n",
    "        return transcript\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading lecture transcript: {e}\")\n",
    "        raise\n",
    "\n",
    "# Load the lecture transcript\n",
    "lecture_transcript = load_lecture_transcript(LECTURE_TRANSCRIPT_PATH)\n",
    "print(f\"\\nFirst 500 characters of transcript:\\n{lecture_transcript[:500]}...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "74a7b5e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 123 student summaries\n",
      "\n",
      "Columns found: ['Timestamp', 'Email Address', 'Name of the Student', 'Roll Number', 'Institute', 'Summary( upto 100words)']\n",
      "\n",
      "First few rows:\n",
      "                Timestamp                  Email Address Name of the Student  \\\n",
      "0 2025-08-23 10:09:12.627          cs22b1024@iiitr.ac.in      Deepak sharma    \n",
      "1 2025-08-23 10:09:17.939  jyoti.24phdcs08@iiitdwd.ac.in         Jyoti Gadad   \n",
      "2 2025-08-23 10:11:19.641          cs22b1003@iiitr.ac.in       Aditya Gupta    \n",
      "3 2025-08-23 10:15:00.025          cs22b1007@iiitr.ac.in      Aman Chaurasia   \n",
      "4 2025-08-23 10:20:59.063         23bds032@iiitdwd.ac.in      Manikesh Kumar   \n",
      "\n",
      "  Roll Number     Institute                            Summary( upto 100words)  \n",
      "0  Cs22b1024   IIIT Raichur  We studied model selection from a wide range o...  \n",
      "1   24PHDCS08  IIIT Dharwad  LangChain helps in building pipelines where an...  \n",
      "2  Cs22b1003   IIIT Raichur  In today’s session, we focused on model select...  \n",
      "3   CS22B1007  IIIT Raichur  Today, I learned about the implementation of c...  \n",
      "4    23bds032  IIIT Dharwad  Prompt engineering, LLM model, knowledge, fine...  \n"
     ]
    }
   ],
   "source": [
    "def load_student_summaries(excel_path):\n",
    "    \"\"\"\n",
    "    Load student summaries from an Excel file.\n",
    "    \n",
    "    Args:\n",
    "        excel_path (str): Path to the Excel file\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame containing student information and summaries\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if not os.path.exists(excel_path):\n",
    "            raise FileNotFoundError(f\"Student summaries file not found: {excel_path}\")\n",
    "        \n",
    "        df = pd.read_excel(excel_path)\n",
    "        \n",
    "        # Validate that DataFrame is not empty\n",
    "        if len(df) == 0:\n",
    "            raise ValueError(\"Student summaries file is empty. Please check the file.\")\n",
    "        \n",
    "        # Expected columns: Email Address, Name of the Student, Roll Number, Institute, Summary\n",
    "        print(f\"Loaded {len(df)} student summaries\")\n",
    "        print(f\"\\nColumns found: {list(df.columns)}\")\n",
    "        print(f\"\\nFirst few rows:\")\n",
    "        print(df.head())\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading student summaries: {e}\")\n",
    "        raise\n",
    "\n",
    "# Load student summaries\n",
    "student_df = load_student_summaries(STUDENT_SUMMARIES_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e601d36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Sentence Transformer model...\n",
      "Note: This may take a few minutes on first run as the model downloads (~80MB)\n",
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Initialize Sentence Transformer model for semantic similarity\n",
    "# Using a pre-trained model that works well for semantic similarity tasks\n",
    "print(\"Loading Sentence Transformer model...\")\n",
    "print(\"Note: This may take a few minutes on first run as the model downloads (~80MB)\")\n",
    "try:\n",
    "    model = SentenceTransformer('all-MiniLM-L6-v2')  # Lightweight and effective model\n",
    "    print(\"Model loaded successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"Error loading model: {e}\")\n",
    "    print(\"Please ensure you have an internet connection for the first run.\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38b17955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 50 key points from the lecture transcript\n",
      "\n",
      "Sample key points:\n",
      "['Agentic AI (2025-08-23 09:02 GMT+5:30) - Transcript Attendees A M D PRADEEP, ABHAY TIWARI, ABHISHEK BUDDIGA, AMAN CHAURASIA, AMOD ADARSH, Amrita Kadam, AMRITA KADAM, ANNEM VENKATA KISHAN KUMAR REDDY IIIT Dharwad, ANUJA GUPTA, ARAVIND BASINI, ARYAN PRATIK, Ashutosh G Singh, ATLA SMARAN REDDY, AVISHAKULA JEEVAN KUMAR, BADA POOJITHA, BANDARU USHA NAGA SRI, BASWA TANUSREE REDDY, BOBBALACHINNOLLA JASWANTH REDDY, BONGU ASHISH IIIT Dharwad, BYREDDY VASUDEVA REDDY, CHAITRA V KATTIMANI IIIT Dharwad, DARSHAN GOWDA D S, DEBOJYOTI ROY, DEEPAK KUMAR, DEEPAK SHARMA, DESAI KARTIK AMIT, DEVA ANAND M, GAIKWAD MANISH BABAN, GANGULA SAICHARAN REDDY, GOGA JAYA SANKEERTH IIIT Dharwad, GUGULOTH JASHWANTH, HARSHAVARDHANA BABU, HEMANT PARTE, HITIK ADWANI IIIT Dharwad, Indi Jayashree M, INTURI MOKSHAGNA IIIT Dharwad, JAKKIREDDY GANESH KUMAR REDDY IIIT Dharwad, JATAVATH DEEPTHI BAI, Jyothi Gadad IIIT Dharwad, K V Jaya Harsha, KAGANA AKSHAY KUMAR, KAMBLE SAKSHAM SUCHIVRAT IIIT Dharwad, KANKIPATI ABISHAI, KAUSTUBH DESHMUKH, KOLIPAKA SATHYA MEENAN, KOMMANA MEGHANA IIIT Dharwad, KOTA VIJAY NARASIMHA GOWD, KRISHU PATEL, KUMARI SEJAL SHAH, KUNAL KUMAR SHAW, KURAPATI SOMA VENKATA SEKHAR, L Sree Lalith Karthik, Madhu Ramesh Koravannavar, MANISH GOWDA, Manvi Singh, MANYAM JAGADEESWAR REDDY IIIT Dharwad, MODINE KARTHIK, MOULI GHOSH, NACHIKET GANESH APTE IIIT Dharwad, NALLA S VEERA VENKATA SATYANARAYANA MURTHY, NALLURI SAI KIRAN, Naumisharanya Tirth, NELABHOTLA ANAND SIVA RAM, NIKHIL NAGAR, NIRBHAY GUPTA IIIT Dharwad, OMKAR LAKHUTE IIIT Dharwad, OPPURI VINAY REDDY, PACHABHATLA DHANUSH, PALEM LOHITH KUMAR, Palshini B Limbani IIIT Dharwad, Pavan Kumar, PRAMOD KHATIK, PRANAY CHENNAMALLA IIIT Dharwad, Prasad K IIIT Dharwad, pratibha Padaki, PRIYAKRITH P S, PRIYANSH AGARWAL, PYLA CHARUKESH, Ranjana Rajput, S NOMTHA PRAKASH IIIT Dharwad, SATYAJEET DAS, Senthil Kumaran Srinivasan, SHAIK SAJID, Shruthi BS, soham bit, Soham Umbare, SRIDHARALA CHIDVILASINI, SRIJAN SHUKLA IIIT Dharwad, Srinivas chavan, SUDARSHAN A, Sunil Saumya, SUNKARA JASWANTH CHOWDARY, SURYANSH AYUSH IIIT Dharwad, SWARUP G L, Swastik', \"Then we saw that for the different use cases How to use this instruction? You can see that instruction doesn't have any fixed place\", 'Sunil Saumya: You can start with one simple instruction and then just add few more means pointers like persona in the next case context and tone and see that okay how the output is coming whether it is what you want or it is not up to the mark and then you can keep on changing that one']\n"
     ]
    }
   ],
   "source": [
    "def extract_key_points(transcript, max_sentences=50):\n",
    "    \"\"\"\n",
    "    Extract key points from the lecture transcript by splitting into sentences\n",
    "    and identifying important sections.\n",
    "    \n",
    "    Args:\n",
    "        transcript (str): Full lecture transcript text\n",
    "        max_sentences (int): Maximum number of sentences to consider\n",
    "    \n",
    "    Returns:\n",
    "        list: List of key sentences/points from the transcript\n",
    "    \"\"\"\n",
    "    # Split transcript into sentences\n",
    "    sentences = transcript.replace('\\n', ' ').split('.')\n",
    "    sentences = [s.strip() for s in sentences if len(s.strip()) > 20]  # Filter very short sentences\n",
    "    \n",
    "    # Take a representative sample of sentences (beginning, middle, end)\n",
    "    if len(sentences) > max_sentences:\n",
    "        # Sample from different parts of the transcript\n",
    "        step = len(sentences) // max_sentences\n",
    "        key_sentences = sentences[::step][:max_sentences]\n",
    "    else:\n",
    "        key_sentences = sentences\n",
    "    \n",
    "    return key_sentences\n",
    "\n",
    "# Extract key points from lecture transcript\n",
    "key_points = extract_key_points(lecture_transcript)\n",
    "print(f\"Extracted {len(key_points)} key points from the lecture transcript\")\n",
    "print(f\"\\nSample key points:\\n{key_points[:3]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ff5273b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation functions defined successfully!\n"
     ]
    }
   ],
   "source": [
    "def calculate_semantic_coverage(summary, key_points, model):\n",
    "    \"\"\"\n",
    "    Calculates a robust score for semantic coverage.\n",
    "    \n",
    "    Compares each key point against each sentence in the summary\n",
    "    to find the best possible match.\n",
    "    \n",
    "    Args:\n",
    "        summary (str): Student's summary text\n",
    "        key_points (list): List of key points from the lecture\n",
    "        model: SentenceTransformer model\n",
    "    \n",
    "    Returns:\n",
    "        float: A score (0-1) representing the average \"best match\" \n",
    "               similarity for all key points.\n",
    "    \"\"\"\n",
    "    if not summary or not key_points or len(summary.strip()) < 10:\n",
    "        return 0.0\n",
    "\n",
    "    # 1. Split summary into sentences and get embeddings\n",
    "    summary_sentences = split_into_sentences(summary)\n",
    "    if not summary_sentences:\n",
    "        return 0.0\n",
    "    \n",
    "    summary_embeddings = model.encode(summary_sentences, \n",
    "                                      convert_to_numpy=True, \n",
    "                                      show_progress_bar=False)\n",
    "\n",
    "    # 2. Get embeddings for all key points\n",
    "    key_point_embeddings = model.encode(key_points, \n",
    "                                        convert_to_numpy=True, \n",
    "                                        show_progress_bar=False)\n",
    "\n",
    "    best_match_scores = []\n",
    "\n",
    "    # 3. For each key point, find its best match in the summary sentences\n",
    "    for key_point_emb in key_point_embeddings:\n",
    "        # Calculate similarity between this key point and ALL summary sentences\n",
    "        similarities = cosine_similarity([key_point_emb], summary_embeddings)[0]\n",
    "        \n",
    "        # Find the highest similarity (the best match for this key point)\n",
    "        best_match = np.max(similarities)\n",
    "        best_match_scores.append(best_match)\n",
    "    \n",
    "    # 4. The final score is the average of all \"best match\" scores\n",
    "    if not best_match_scores:\n",
    "        return 0.0\n",
    "        \n",
    "    coverage_score = np.mean(best_match_scores)\n",
    "    \n",
    "    return float(coverage_score)\n",
    "\n",
    "\n",
    "def calculate_clarity_score(summary):\n",
    "    \"\"\"\n",
    "    Calculate clarity and coherence score based on text characteristics.\n",
    "    (This function is unchanged)\n",
    "    \n",
    "    Args:\n",
    "        summary (str): Student's summary text\n",
    "    \n",
    "    Returns:\n",
    "        float: Clarity score between 0 and 1\n",
    "    \"\"\"\n",
    "    if not summary or len(summary.strip()) < 10:\n",
    "        return 0.0\n",
    "    \n",
    "    # Basic heuristics for clarity\n",
    "    word_count = len(summary.split())\n",
    "    sentence_count = len(split_into_sentences(summary)) # Use new sentence splitter\n",
    "    \n",
    "    # Check for reasonable sentence length (not too short, not too long)\n",
    "    avg_sentence_length = word_count / max(sentence_count, 1)\n",
    "    \n",
    "    # Score based on:\n",
    "    # - Has reasonable length (not too short, not too verbose)\n",
    "    # - Has multiple sentences (shows structure)\n",
    "    # - Average sentence length is reasonable (10-25 words is good)\n",
    "    \n",
    "    length_score = min(1.0, word_count / 100)  # Prefer summaries with at least 100 words\n",
    "    structure_score = min(1.0, sentence_count / 5)  # Prefer at least 5 sentences\n",
    "    sentence_quality = 1.0 if 10 <= avg_sentence_length <= 30 else 0.7\n",
    "    \n",
    "    # Combined clarity score\n",
    "    clarity = (length_score * 0.3 + structure_score * 0.3 + sentence_quality * 0.4)\n",
    "    \n",
    "    return min(clarity, 1.0)\n",
    "\n",
    "\n",
    "def check_grammar_basic(summary):\n",
    "    \"\"\"\n",
    "    Basic grammar check using simple heuristics.\n",
    "    (This function is unchanged, but uses the new sentence splitter)\n",
    "    \n",
    "    Args:\n",
    "        summary (str): Student's summary text\n",
    "    \n",
    "    Returns:\n",
    "        float: Grammar score between 0 and 1\n",
    "    \"\"\"\n",
    "    if not summary or len(summary.strip()) < 10:\n",
    "        return 0.0\n",
    "    \n",
    "    # Basic checks:\n",
    "    # - Proper capitalization at sentence start\n",
    "    # - No excessive repeated characters\n",
    "    \n",
    "    sentences = split_into_sentences(summary) # Use new sentence splitter\n",
    "    if not sentences:\n",
    "        return 0.0\n",
    "    \n",
    "    proper_caps = sum(1 for s in sentences if s and s[0].isupper()) / len(sentences)\n",
    "    \n",
    "    # Check for excessive repetition (e.g., \"aaaa\")\n",
    "    has_repetition = any(len(set(word)) == 1 and len(word) > 3 for word in summary.split())\n",
    "    repetition_penalty = 0.0 if has_repetition else 1.0\n",
    "    \n",
    "    grammar_score = (proper_caps * 0.7 + repetition_penalty * 0.3)\n",
    "    \n",
    "    return grammar_score\n",
    "\n",
    "print(\"Evaluation functions defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d874ab6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence splitting helper function defined (using Regex, not NLTK)!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def split_into_sentences(text):\n",
    "    \"\"\"\n",
    "    Splits a block of text into a list of sentences using regex.\n",
    "    This function NO LONGER uses NLTK.\n",
    "    \"\"\"\n",
    "    if not text or len(text.strip()) == 0:\n",
    "        return []\n",
    "    \n",
    "    # Split using regex: split after a period, ?, or ! followed by a space or newline\n",
    "    sentences = re.split(r'(?<=[.!?])[\\s\\n]+', text)\n",
    "    \n",
    "    # Clean up and filter out very short sentences\n",
    "    cleaned_sentences = [s.strip() for s in sentences if s and len(s.strip()) > 10]\n",
    "    return cleaned_sentences\n",
    "\n",
    "print(\"Sentence splitting helper function defined (using Regex, not NLTK)!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b6879dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation functions defined successfully (WITH NEW, LOWER SCALING)!\n"
     ]
    }
   ],
   "source": [
    "# THIS IS THE REPLACEMENT FOR YOUR \"EVALUATION FUNCTION\" CELL (CELL 6)\n",
    "\n",
    "def calculate_semantic_coverage(summary, key_points, model):\n",
    "    \"\"\"\n",
    "    Calculates a robust AND SCALED score for semantic coverage.\n",
    "    \n",
    "    The final \"raw\" score is scaled to fit a 0-1 grading range.\n",
    "    \n",
    "    Args:\n",
    "        summary (str): Student's summary text\n",
    "        key_points (list): List of key points from the lecture\n",
    "        model: SentenceTransformer model\n",
    "    \n",
    "    Returns:\n",
    "        float: A SCALED score (0-1) representing coverage.\n",
    "    \"\"\"\n",
    "    if not summary or not key_points or len(summary.strip()) < 10:\n",
    "        return 0.0\n",
    "\n",
    "    # 1. Split summary into sentences and get embeddings\n",
    "    summary_sentences = split_into_sentences(summary) # This function is in another cell\n",
    "    if not summary_sentences:\n",
    "        return 0.0\n",
    "    \n",
    "    summary_embeddings = model.encode(summary_sentences, \n",
    "                                      convert_to_numpy=True, \n",
    "                                      show_progress_bar=False)\n",
    "\n",
    "    # 2. Get embeddings for all key points\n",
    "    key_point_embeddings = model.encode(key_points, \n",
    "                                        convert_to_numpy=True, \n",
    "                                        show_progress_bar=False)\n",
    "\n",
    "    best_match_scores = []\n",
    "\n",
    "    # 3. For each key point, find its best match in the summary sentences\n",
    "    for key_point_emb in key_point_embeddings:\n",
    "        similarities = cosine_similarity([key_point_emb], summary_embeddings)[0]\n",
    "        best_match = np.max(similarities)\n",
    "        best_match_scores.append(best_match)\n",
    "    \n",
    "    # 4. The raw score is the average of all \"best match\" scores\n",
    "    if not best_match_scores:\n",
    "        return 0.0\n",
    "        \n",
    "    raw_coverage_score = np.mean(best_match_scores)\n",
    "    \n",
    "    # --- 5. NEW, MORE GENEROUS SCALING ---\n",
    "    # The raw scores are very low. We will map a much\n",
    "    # lower range to the 0.0 to 1.0 grade.\n",
    "    \n",
    "    # *** YOU CAN TUNE THESE TWO NUMBERS ***\n",
    "    # Make them lower to give higher grades.\n",
    "    # Make them higher to give lower grades.\n",
    "    MIN_SIMILARITY_THRESHOLD = 0.1   # The raw score that maps to 0.0\n",
    "    MAX_SIMILARITY_THRESHOLD = 0.35  # The raw score that maps to 1.0\n",
    "    \n",
    "    if raw_coverage_score < MIN_SIMILARITY_THRESHOLD:\n",
    "        scaled_score = 0.0\n",
    "    elif raw_coverage_score > MAX_SIMILARITY_THRESHOLD:\n",
    "        scaled_score = 1.0\n",
    "    else:\n",
    "        # Linear scaling\n",
    "        scaled_score = (raw_coverage_score - MIN_SIMILARITY_THRESHOLD) / (MAX_SIMILARITY_THRESHOLD - MIN_SIMILARITY_THRESHOLD)\n",
    "        \n",
    "    scaled_score = np.clip(scaled_score, 0, 1)\n",
    "\n",
    "    return float(scaled_score)\n",
    "\n",
    "\n",
    "# --- THE FUNCTIONS BELOW ARE UNCHANGED ---\n",
    "# (They must be in the same cell)\n",
    "\n",
    "def calculate_clarity_score(summary):\n",
    "    if not summary or len(summary.strip()) < 10:\n",
    "        return 0.0\n",
    "    word_count = len(summary.split())\n",
    "    sentence_count = len(split_into_sentences(summary)) \n",
    "    avg_sentence_length = word_count / max(sentence_count, 1)\n",
    "    length_score = min(1.0, word_count / 100)\n",
    "    structure_score = min(1.0, sentence_count / 5)\n",
    "    sentence_quality = 1.0 if 10 <= avg_sentence_length <= 30 else 0.7\n",
    "    clarity = (length_score * 0.3 + structure_score * 0.3 + sentence_quality * 0.4)\n",
    "    return min(clarity, 1.0)\n",
    "\n",
    "\n",
    "def check_grammar_basic(summary):\n",
    "    if not summary or len(summary.strip()) < 10:\n",
    "        return 0.0\n",
    "    sentences = split_into_sentences(summary) \n",
    "    if not sentences:\n",
    "        return 0.0\n",
    "    proper_caps = sum(1 for s in sentences if s and s[0].isupper()) / len(sentences)\n",
    "    has_repetition = any(len(set(word)) == 1 and len(word) > 3 for word in summary.split())\n",
    "    repetition_penalty = 0.0 if has_repetition else 1.0\n",
    "    grammar_score = (proper_caps * 0.7 + repetition_penalty * 0.3)\n",
    "    return grammar_score\n",
    "\n",
    "print(\"Evaluation functions defined successfully (WITH NEW, LOWER SCALING)!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c03d2894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Main evaluation function defined successfully!\n"
     ]
    }
   ],
   "source": [
    "def generate_explanation(score, semantic_coverage, clarity, completeness, grammar, summary, word_count):\n",
    "    \"\"\"\n",
    "    Generate a 2-3 sentence explanation justifying the score.\n",
    "    (UPDATED to use new 'semantic_coverage' score)\n",
    "    \n",
    "    Args:\n",
    "        score (float): Final score out of 10\n",
    "        semantic_coverage (float): The new combined coverage/similarity score\n",
    "        clarity (float): Clarity score\n",
    "        completeness (float): Completeness score\n",
    "        grammar (float): Grammar score\n",
    "        summary (str): The summary text\n",
    "        word_count (int): Word count of summary\n",
    "    \n",
    "    Returns:\n",
    "        str: Explanation text\n",
    "    \"\"\"\n",
    "    strengths = []\n",
    "    weaknesses = []\n",
    "    \n",
    "    # Identify strengths\n",
    "    if semantic_coverage > 0.6:\n",
    "        strengths.append(\"covers most key lecture points well\")\n",
    "    elif semantic_coverage > 0.4:\n",
    "        strengths.append(\"covers some key lecture points\")\n",
    "\n",
    "    if clarity > 0.7:\n",
    "        strengths.append(\"demonstrates clear and coherent writing\")\n",
    "    \n",
    "    if grammar > 0.8:\n",
    "        strengths.append(\"shows good grammatical structure\")\n",
    "    \n",
    "    # Identify weaknesses\n",
    "    if semantic_coverage < 0.3:\n",
    "        weaknesses.append(\"omits many key lecture points and shows limited alignment with lecture content\")\n",
    "    elif semantic_coverage < 0.4:\n",
    "        weaknesses.append(\"misses some important lecture points\")\n",
    "    \n",
    "    if clarity < 0.5:\n",
    "        weaknesses.append(\"lacks clarity and coherent structure\")\n",
    "    \n",
    "    if word_count < 50:\n",
    "        weaknesses.append(\"is too brief and lacks detail\")\n",
    "    \n",
    "    if grammar < 0.6:\n",
    "        weaknesses.append(\"contains grammatical issues\")\n",
    "    \n",
    "    # Construct explanation\n",
    "    explanation_parts = []\n",
    "    \n",
    "    if strengths:\n",
    "        explanation_parts.append(f\"The summary {', '.join(strengths[:2])}.\")\n",
    "    \n",
    "    if weaknesses:\n",
    "        explanation_parts.append(f\"However, it {', '.join(weaknesses[:2])}.\")\n",
    "    \n",
    "    if not explanation_parts:\n",
    "        if score >= 7:\n",
    "            explanation_parts.append(\"The summary provides a solid overview of the lecture with good coverage and clarity.\")\n",
    "        elif score >= 4:\n",
    "            explanation_parts.append(\"The summary demonstrates moderate understanding but could benefit from more comprehensive coverage.\")\n",
    "        else:\n",
    "            explanation_parts.append(\"The summary requires significant improvement in coverage, clarity, and alignment with lecture content.\")\n",
    "    \n",
    "    # Add score context\n",
    "    if score >= 8:\n",
    "        explanation_parts.append(\"Overall, this represents a strong summary that effectively captures the lecture's main points.\")\n",
    "    elif score >= 6:\n",
    "        explanation_parts.append(\"The summary meets basic requirements but has room for improvement in depth and completeness.\")\n",
    "    elif score >= 4:\n",
    "        explanation_parts.append(\"The summary shows partial understanding but lacks sufficient detail and coverage.\")\n",
    "    else:\n",
    "        explanation_parts.append(\"The summary needs substantial revision to adequately represent the lecture content.\")\n",
    "    \n",
    "    return \" \".join(explanation_parts)\n",
    "\n",
    "\n",
    "def evaluate_summary(summary, lecture_transcript, key_points, model):\n",
    "    \"\"\"\n",
    "    Comprehensive evaluation of a student summary against the lecture transcript.\n",
    "    (UPDATED to use new 'calculate_semantic_coverage' function and new weights)\n",
    "    \n",
    "    Args:\n",
    "        summary (str): Student's summary text\n",
    "        lecture_transcript (str): Full lecture transcript (unused, but kept for compatibility)\n",
    "        key_points (list): List of key points from the lecture\n",
    "        model: SentenceTransformer model for embeddings\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (score out of 10, explanation string)\n",
    "    \"\"\"\n",
    "    if not summary or len(summary.strip()) < 10:\n",
    "        return 0.0, \"Summary is too short or empty. No meaningful content provided.\"\n",
    "    \n",
    "    # Calculate individual component scores (all between 0 and 1)\n",
    "    \n",
    "    # 1. NEW: Semantic Coverage (Replaces old 'similarity' and 'coverage')\n",
    "    # This is now the main semantic score, comparing summary sentences to key points.\n",
    "    semantic_coverage = calculate_semantic_coverage(summary, key_points, model)\n",
    "    \n",
    "    # 2. Clarity and coherence\n",
    "    clarity_score = calculate_clarity_score(summary)\n",
    "    \n",
    "    # 3. Grammar (basic check)\n",
    "    grammar_score = check_grammar_basic(summary)\n",
    "    \n",
    "    # 4. Completeness (based on length and NEW coverage score)\n",
    "    word_count = len(summary.split())\n",
    "    completeness_score = min(1.0, (semantic_coverage * 0.7 + min(1.0, word_count / 200) * 0.3))\n",
    "    \n",
    "    # Weighted combination of scores\n",
    "    # Semantic Coverage: 55% (Combined 30% Coverage + 25% Similarity)\n",
    "    # Clarity: 20%\n",
    "    # Completeness: 15%\n",
    "    # Grammar: 10%\n",
    "    final_score = (\n",
    "        semantic_coverage * 0.55 +\n",
    "        clarity_score * 0.20 +\n",
    "        completeness_score * 0.15 +\n",
    "        grammar_score * 0.10\n",
    "    )\n",
    "    \n",
    "    # Convert to 0-10 scale\n",
    "    score_0_10 = final_score * 10\n",
    "    \n",
    "    # Generate explanation\n",
    "    explanation = generate_explanation(\n",
    "        score_0_10, semantic_coverage, clarity_score, \n",
    "        completeness_score, grammar_score, summary, word_count\n",
    "    )\n",
    "    \n",
    "    return round(score_0_10, 1), explanation\n",
    "\n",
    "print(\"Main evaluation function defined successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fe3b8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting batch processing of all student summaries...\n",
      "Using column 'Summary( upto 100words)' for summaries\n",
      "\n",
      "Processing 123 summaries...\n",
      "Processing student 123/123...\n",
      "\n",
      "Completed processing all 123 summaries!\n"
     ]
    }
   ],
   "source": [
    "def process_all_summaries(student_df, lecture_transcript, key_points, model):\n",
    "    \"\"\"\n",
    "    Process all student summaries and generate scores and explanations.\n",
    "    \n",
    "    Args:\n",
    "        student_df (pd.DataFrame): DataFrame with student information and summaries\n",
    "        lecture_transcript (str): Full lecture transcript\n",
    "        key_points (list): List of key points from the lecture\n",
    "        model: SentenceTransformer model\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: DataFrame with all original columns plus Score and Explanation\n",
    "    \"\"\"\n",
    "    # Validate inputs\n",
    "    if student_df is None or len(student_df) == 0:\n",
    "        raise ValueError(\"Student DataFrame is empty or None\")\n",
    "    \n",
    "    if not lecture_transcript or len(lecture_transcript.strip()) < 50:\n",
    "        raise ValueError(\"Lecture transcript is empty or too short\")\n",
    "    \n",
    "    if not key_points or len(key_points) == 0:\n",
    "        raise ValueError(\"No key points extracted from lecture transcript\")\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    # Determine the summary column name (handle variations)\n",
    "    summary_col = None\n",
    "    possible_names = ['Summary', 'summary', 'Summary Text', 'Student Summary']\n",
    "    for name in possible_names:\n",
    "        if name in student_df.columns:\n",
    "            summary_col = name\n",
    "            break\n",
    "    \n",
    "    if summary_col is None:\n",
    "        # Try to find a column that might contain summaries\n",
    "        for col in student_df.columns:\n",
    "            if 'summary' in col.lower():\n",
    "                summary_col = col\n",
    "                break\n",
    "    \n",
    "    if summary_col is None:\n",
    "        raise ValueError(f\"Could not find summary column. Available columns: {list(student_df.columns)}\")\n",
    "    \n",
    "    print(f\"Using column '{summary_col}' for summaries\")\n",
    "    print(f\"\\nProcessing {len(student_df)} summaries...\")\n",
    "    \n",
    "    for idx, row in student_df.iterrows():\n",
    "        # Handle NaN and None values\n",
    "        summary = str(row[summary_col]) if pd.notna(row[summary_col]) else \"\"\n",
    "        summary = summary.strip() if summary else \"\"\n",
    "        \n",
    "        print(f\"Processing student {idx + 1}/{len(student_df)}...\", end=\"\\r\")\n",
    "        \n",
    "        try:\n",
    "            # Evaluate the summary\n",
    "            score, explanation = evaluate_summary(summary, lecture_transcript, key_points, model)\n",
    "        except Exception as e:\n",
    "            print(f\"\\nWarning: Error evaluating summary for student {idx + 1}: {e}\")\n",
    "            score = 0.0\n",
    "            explanation = f\"Error during evaluation: {str(e)}\"\n",
    "        \n",
    "        # Create result row - preserve all original columns\n",
    "        result_row = row.to_dict()\n",
    "        result_row['Numerical Score'] = score\n",
    "        result_row['Short explanation'] = explanation\n",
    "        \n",
    "        results.append(result_row)\n",
    "    \n",
    "    print(f\"\\n\\nCompleted processing all {len(student_df)} summaries!\")\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    if not results:\n",
    "        raise ValueError(\"No results generated. Please check your input data.\")\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    \n",
    "    return results_df\n",
    "\n",
    "# Process all summaries\n",
    "print(\"Starting batch processing of all student summaries...\")\n",
    "graded_results = process_all_summaries(student_df, lecture_transcript, key_points, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78492741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output DataFrame prepared!\n",
      "\n",
      "Columns: ['Email Address', 'Name', 'Roll Number', 'Institute', 'Original Summary', 'Numerical Score', 'Short explanation']\n",
      "\n",
      "Shape: (123, 7)\n",
      "\n",
      "First few rows:\n",
      "                   Email Address            Name Roll Number     Institute  \\\n",
      "0          cs22b1024@iiitr.ac.in  Deepak sharma   Cs22b1024   IIIT Raichur   \n",
      "1  jyoti.24phdcs08@iiitdwd.ac.in     Jyoti Gadad   24PHDCS08  IIIT Dharwad   \n",
      "2          cs22b1003@iiitr.ac.in   Aditya Gupta   Cs22b1003   IIIT Raichur   \n",
      "3          cs22b1007@iiitr.ac.in  Aman Chaurasia   CS22B1007  IIIT Raichur   \n",
      "4         23bds032@iiitdwd.ac.in  Manikesh Kumar    23bds032  IIIT Dharwad   \n",
      "\n",
      "                                    Original Summary  Numerical Score  \\\n",
      "0  We studied model selection from a wide range o...              4.6   \n",
      "1  LangChain helps in building pipelines where an...              8.1   \n",
      "2  In today’s session, we focused on model select...              6.6   \n",
      "3  Today, I learned about the implementation of c...              5.1   \n",
      "4  Prompt engineering, LLM model, knowledge, fine...              6.5   \n",
      "\n",
      "                                   Short explanation  \n",
      "0  The summary shows good grammatical structure. ...  \n",
      "1  The summary covers most key lecture points wel...  \n",
      "2  The summary covers some key lecture points, de...  \n",
      "3  The summary demonstrates clear and coherent wr...  \n",
      "4  The summary covers some key lecture points, de...  \n"
     ]
    }
   ],
   "source": [
    "def prepare_output_dataframe(graded_results):\n",
    "    \"\"\"\n",
    "    Prepare the final output DataFrame with all required columns in the correct order.\n",
    "    \n",
    "    Args:\n",
    "        graded_results (pd.DataFrame): DataFrame with graded results\n",
    "    \n",
    "    Returns:\n",
    "        pd.DataFrame: Formatted output DataFrame\n",
    "    \"\"\"\n",
    "    # Validate that required columns exist\n",
    "    if 'Numerical Score' not in graded_results.columns:\n",
    "        raise ValueError(\"Missing 'Numerical Score' column in graded results\")\n",
    "    if 'Short explanation' not in graded_results.columns:\n",
    "        raise ValueError(\"Missing 'Short explanation' column in graded results\")\n",
    "    \n",
    "    # Map column names (handle variations)\n",
    "    column_mapping = {\n",
    "        'Email Address': ['Email Address', 'Email', 'email', 'Email address', 'Email Address'],\n",
    "        'Name': ['Name of the Student', 'Name', 'Student Name', 'name', 'Name of Student'],\n",
    "        'Roll Number': ['Roll Number', 'Roll No', 'Roll', 'roll number', 'RollNumber'],\n",
    "        'Institute': ['Institute', 'institute', 'Institution', 'Institution Name'],\n",
    "        'Original Summary': None,  # Will be determined from summary column\n",
    "        'Numerical Score': 'Numerical Score',\n",
    "        'Short explanation': 'Short explanation'\n",
    "    }\n",
    "    \n",
    "    output_data = {}\n",
    "    \n",
    "    # Find and map columns\n",
    "    for target_col, possible_names in column_mapping.items():\n",
    "        if possible_names is None:\n",
    "            # Special handling for Original Summary\n",
    "            summary_col = None\n",
    "            for col in graded_results.columns:\n",
    "                if 'summary' in col.lower() and col not in ['Short explanation', 'Short Explanation']:\n",
    "                    summary_col = col\n",
    "                    break\n",
    "            if summary_col:\n",
    "                output_data[target_col] = graded_results[summary_col].fillna(\"\")\n",
    "            else:\n",
    "                # Create empty column if summary column not found\n",
    "                output_data[target_col] = [\"\"] * len(graded_results)\n",
    "        else:\n",
    "            found = False\n",
    "            for possible_name in possible_names:\n",
    "                if possible_name in graded_results.columns:\n",
    "                    # Fill NaN values with empty string\n",
    "                    output_data[target_col] = graded_results[possible_name].fillna(\"\")\n",
    "                    found = True\n",
    "                    break\n",
    "            if not found:\n",
    "                # If column not found, create empty column\n",
    "                output_data[target_col] = [\"\"] * len(graded_results)\n",
    "    \n",
    "    # Ensure all columns have the same length\n",
    "    expected_length = len(graded_results)\n",
    "    for key, value in output_data.items():\n",
    "        if isinstance(value, pd.Series):\n",
    "            if len(value) != expected_length:\n",
    "                raise ValueError(f\"Column '{key}' has incorrect length: {len(value)} != {expected_length}\")\n",
    "        elif isinstance(value, list):\n",
    "            if len(value) != expected_length:\n",
    "                output_data[key] = [\"\"] * expected_length\n",
    "    \n",
    "    # Create output DataFrame with required columns in order\n",
    "    output_df = pd.DataFrame({\n",
    "        'Email Address': output_data.get('Email Address', [\"\"] * expected_length),\n",
    "        'Name': output_data.get('Name', [\"\"] * expected_length),\n",
    "        'Roll Number': output_data.get('Roll Number', [\"\"] * expected_length),\n",
    "        'Institute': output_data.get('Institute', [\"\"] * expected_length),\n",
    "        'Original Summary': output_data.get('Original Summary', [\"\"] * expected_length),\n",
    "        'Numerical Score': graded_results['Numerical Score'],\n",
    "        'Short explanation': graded_results['Short explanation']\n",
    "    })\n",
    "    \n",
    "    # Validate output DataFrame\n",
    "    if len(output_df) == 0:\n",
    "        raise ValueError(\"Output DataFrame is empty\")\n",
    "    \n",
    "    return output_df\n",
    "\n",
    "# Prepare output DataFrame\n",
    "output_df = prepare_output_dataframe(graded_results)\n",
    "\n",
    "print(\"Output DataFrame prepared!\")\n",
    "print(f\"\\nColumns: {list(output_df.columns)}\")\n",
    "print(f\"\\nShape: {output_df.shape}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "print(output_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "884dd8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully exported results to Gradedresults_23rd_august.xlsx\n",
      "Total students graded: 123\n",
      "\n",
      "Score statistics:\n",
      "  Mean: 7.03\n",
      "  Min: 3.60\n",
      "  Max: 9.80\n",
      "  Std: 1.16\n",
      "  File size: 37.50 KB\n",
      "\n",
      "==================================================\n",
      "GRADING COMPLETE!\n",
      "==================================================\n",
      "Output file: Gradedresults_23rd_august.xlsx\n",
      "File location: c:\\Users\\jallu\\OneDrive\\Desktop\\Quiz\\Gradedresults_23rd_august.xlsx\n"
     ]
    }
   ],
   "source": [
    "def export_to_excel(output_df, output_path):\n",
    "    \"\"\"\n",
    "    Export the graded results to an Excel file.\n",
    "    \n",
    "    Args:\n",
    "        output_df (pd.DataFrame): DataFrame with graded results\n",
    "        output_path (str): Path to output Excel file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Validate DataFrame before export\n",
    "        if output_df is None or len(output_df) == 0:\n",
    "            raise ValueError(\"Cannot export empty DataFrame\")\n",
    "        \n",
    "        # Check if required columns exist\n",
    "        required_cols = ['Email Address', 'Name', 'Roll Number', 'Institute', \n",
    "                        'Original Summary', 'Numerical Score', 'Short explanation']\n",
    "        missing_cols = [col for col in required_cols if col not in output_df.columns]\n",
    "        if missing_cols:\n",
    "            raise ValueError(f\"Missing required columns: {missing_cols}\")\n",
    "        \n",
    "        # Ensure output directory exists\n",
    "        output_dir = os.path.dirname(output_path) if os.path.dirname(output_path) else \".\"\n",
    "        if output_dir and not os.path.exists(output_dir):\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "        \n",
    "        # Export to Excel\n",
    "        output_df.to_excel(output_path, index=False, engine='openpyxl')\n",
    "        \n",
    "        # Verify file was created\n",
    "        if not os.path.exists(output_path):\n",
    "            raise FileNotFoundError(f\"Output file was not created: {output_path}\")\n",
    "        \n",
    "        print(f\"\\nSuccessfully exported results to {output_path}\")\n",
    "        print(f\"Total students graded: {len(output_df)}\")\n",
    "        print(f\"\\nScore statistics:\")\n",
    "        print(f\"  Mean: {output_df['Numerical Score'].mean():.2f}\")\n",
    "        print(f\"  Min: {output_df['Numerical Score'].min():.2f}\")\n",
    "        print(f\"  Max: {output_df['Numerical Score'].max():.2f}\")\n",
    "        print(f\"  Std: {output_df['Numerical Score'].std():.2f}\")\n",
    "        \n",
    "        # Show file size\n",
    "        file_size = os.path.getsize(output_path) / 1024  # KB\n",
    "        print(f\"  File size: {file_size:.2f} KB\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error exporting to Excel: {e}\")\n",
    "        raise\n",
    "\n",
    "# Export results\n",
    "export_to_excel(output_df, OUTPUT_FILE_PATH)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"GRADING COMPLETE!\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Output file: {OUTPUT_FILE_PATH}\")\n",
    "print(f\"File location: {os.path.abspath(OUTPUT_FILE_PATH)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quizenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
